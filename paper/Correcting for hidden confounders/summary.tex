\documentclass[a4paper,tablecaptionabove]{article}

\usepackage{palatino} \usepackage{booktabs}

\usepackage{MnSymbol,amsmath}
\usepackage[autolanguage]{numprint}

\usepackage{graphicx,xcolor}

\usepackage{geometry} \geometry{a4paper,left=30mm,right=35mm,
  top=40mm, bottom=40mm}

\newcommand{\matr}[1]{\ensuremath{\boldsymbol{\mathbf #1}}}
\newcommand{\T}{\ensuremath{^\top}}

\begin{document}

\section{Data}
\label{sec:data}

\begin{table}[h]
  \centering
  \begin{tabular}{lcc}
    \toprule
    Name & Symbol & Dimension\\
    \midrule
    Replicates && $R$  \\
    Samples && $N$ \\
    Timepoints && $T$ \\
    Genes && $D$ \\
    Confounders && $Q$ \\
    Expression & $\matr Y$ & $NRT\times D$\\
    Latent Variables of Confounders & $\matr X$ & $NRT\times Q$\\
    Confounders & $\matr C$ & $NRT\times D$\\
    \bottomrule
  \end{tabular}
  \caption{Data explanation}
  \label{tab:data}
\end{table}

\section{Assumption on Confounder influence}
\label{sec:assumpt-conf-infl}

The confounders are assumed to additively contribute to gene
expression:
\begin{equation}
  \label{eq:5}
  \matr Y = \matr Y_\text{true} + \matr C + \sigma^2\matr I\enspace,
\end{equation}
where in the linear case the confounders are
\begin{equation}
  \label{eq:6}
  \matr C = \matr{XW}
\end{equation}

\section{Confounder Modelling}
\label{sec:confounder-modelling}

\subsection{Linear}
\label{sec:linear}

\begin{align}
  \matr{X} & = \text{randn}(NRT,Q)\\
  \matr{W} & = \text{randn}(Q,D)\\
  \matr{C} & = \matr{XW}
\end{align}

\section{Model Ideas:}
\label{sec:model-ideas}

\subsection{Model 1: Covariance Confounders}
\label{sec:model-1:-covariance}

Learn confounders $\matr{X}$ through GPLVM. Include Condounders as
Covariance Matrix
\begin{equation}
  \label{eq:1}
  \matr K_{\matr X} = \matr X\matr X\T
\end{equation}
into model, as follows:
\begin{equation}
  \label{eq:2}
  p(\matr Y|\matr t,\matr \theta,\matr X) = \prod_d^D\mathcal N(\matr y_d|\matr 0, \matr K_{\matr\theta}(\matr t) + \matr K_{\matr X}+\sigma^2\matr I)\enspace.
\end{equation}

\subsection{Model 2: Added Confounders}
\label{sec:model-2:-added}

Learn confounders $\matr X$ and predict confounder matrix by
GPLVM. Subtract confounder matrix from observed gene expression and
run normal GPTwoSample on residuals.
\begin{align}
  \label{eq:3}
  \matr Y_{\text{non-confounded}} &= \matr Y - \text{GPLVM.predict(\matr X)}\\
  p(\matr Y_{\text{non-confounded}}) &= \prod_d^D\mathcal N(\matr
  y_d|\matr 0, \matr K_{\matr\theta}(\matr t) + \sigma^2\matr
  I)\enspace.
\end{align}

\subsection{Model 3: One Confounder Matrix per Condition}
\label{sec:model-3:-one}

Learn confounders $\matr X_1$ and $\matr X_2$ on condition $\matr Y_1$
and $\matr Y_2$, respectively. Then either predict or incorporate
confounders as covariance into GPTwoSample.

\section{Proof of concept}
\label{sec:proof-concept}

To proof the concept of taking confounder into account we take an
ideal confounder model into account: Put simulated confounders $\matr
X_\text{sim}$ into model and run GPTwoSample with that. The ideal
model should have a similar AUC as the raw model does, because the
confounding variance should be explained by the simulated confounder
matrix and everything other is the same as in raw.

\begin{figure}[h]
  \centering
  \includegraphics[width=.7\textwidth]{../../gptwosample/develop/reveal_confounders_proof_of_concept/roc.pdf}
  \caption{ROC plot for different approaches: conf$\rightarrow$Model
    1, normal$\rightarrow$GPTwoSample applied to confounded
    expression, without confounder correction,
    predict$\rightarrow$Model 2, raw$\rightarrow$GPTwoSample applied
    to non confounded expression, ideal$\rightarrow$ideal
    confounders.}
\end{figure}

% $\Rightarrow$ As the raw model severely outperforms the ideal model, it might not be a good idea to put the learnt covariance directly into GPTwoSample prediction?\\
% $\Rightarrow$ Model 2 proof of concept:\\
% \includegraphics[width=\textwidth]{../../gptwosample/develop/reveal_confounders_proof_of_concept/ideal_prediction.pdf}\\
% Predicting with the ideal model gives simulated confounders with high accuracy (MSD$=\numprint{0.021}$) and low variance (\numprint{7E-7})\\
% $\Rightarrow$ Why does introducing covariance into GPTwoSample does
% not give same results as predicting on raw data? Say we have chosen
% the covariance function as follows:
% \begin{equation}
%   \label{eq:7}
%   \matr K = \alpha_1\matr K_{\matr \theta}(\matr t, \matr t') + \alpha_2 \matr K_{\text{ideal}} + \sigma^2\matr I\enspace,
% \end{equation}
% then: mean $\alpha_1=0.44$ and mean $\alpha_2=10$ ({\color{red}{!}})
% $\Rightarrow$ too much expression variance is explained by
% confounders.

\end{document}